{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction:**\n",
    "\n",
    "This file serves to host an attempted Keras implementation of an Adaptive Neuro-Fuzzy Inference System (ANFIS).\n",
    "\n",
    "**Date Created:** 22/01/2025\n",
    "\n",
    "**Date Modified:** 27/01/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import Packages:**\n",
    "\n",
    "This section imports all the necessary packages for the ANFIS implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages:\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from keras.layers import Layer\n",
    "from tensorflow.keras import Input, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Function & Layer Definition:**\n",
    "\n",
    "This section creates the necessary custom functions and layers for this ANFIS implementation within Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to first define the initial layer -> the membership function layer:\n",
    "class MembershipFunctionLayer(Layer):\n",
    "    # constructor:\n",
    "    def __init__(self, num_inputs, num_mfs, params = None, **kwargs):   # by including **kwargs, we allow for additional arguments from keras, like name or dtype\n",
    "        super(MembershipFunctionLayer, self).__init__(**kwargs)         # we are subclassing from the keras layer -> telling the constructor to make our layer like a keras layer\n",
    "        self.num_inputs = num_inputs            # define the number of inputs to the ANFIS \n",
    "        self.num_mfs = num_mfs                  # define the number of membership functions per input\n",
    "        self.num_rules = num_mfs ** num_inputs  # the number of rules is calculated as such:\n",
    "\n",
    "        # next is the initialization of the antecedent parameters:\n",
    "        if params is not None:\n",
    "            # initialize custom parameters defined by the user:\n",
    "            self.mf_params = self.add_weight(\n",
    "                shape=(self.num_inputs, self.num_mfs, 3),       # define their shape, (num_inputs, num_mfs, 3) as we have 3 params for a triangular mf\n",
    "                initializer=tf.constant_initializer(params),    # initialize as constants from the provided array\n",
    "                trainable=True,                                 # set to trainable\n",
    "                name=\"Antecedent Params\",                       # assign them a name\n",
    "            )\n",
    "            print('Custom parameters have been set.')\n",
    "        else:\n",
    "            # initialize raw membership parameters:\n",
    "            raw_params = self.add_weight(\n",
    "                shape = (self.num_inputs, self.num_mfs, 3),     # define their shape, (num_inputs, num_mfs, 3) as we have 3 params for a triangular mf\n",
    "                initializer = \"random_uniform\",                 # initialize as a random, uniform distribution\n",
    "                trainable = True,                               # set to trainable\n",
    "                name = \"Raw Antecedent Params\",                 # assign them a name \n",
    "            )\n",
    "\n",
    "            # sort the parameters such that a <= b <= c:\n",
    "            sorted_params = tf.sort(raw_params, axis = 1)           # sort such that a <= b <= c\n",
    "            self.mf_params = self.add_weight(                       \n",
    "                shape = (self.num_inputs, self.num_mfs, 3),                     # set the shape: (num_inputs, num_mfs, 3) as we have 3 params for a triangular mf\n",
    "                initializer = tf.constant_initializer(sorted_params.numpy()),   # initialize as the sorted array of params\n",
    "                trainable = True,                                               # set to trainable\n",
    "                name = 'Antecedent Params'                                      # assign them a name\n",
    "            )\n",
    "            print('Random parameters have been set.')\n",
    "\n",
    "    # define the triangular membership function within this layer as this is where it is used:\n",
    "    def triangular_membership(self, x, params):\n",
    "        a, b, c = params        # load params\n",
    "\n",
    "        # throw error if not a < b < c:\n",
    "        if a > b or b > c:\n",
    "            raise ValueError(\"Invalid parameters: Ensure a < b < c.\") \n",
    "    \n",
    "        if a == b:  # rising ramp (plateau at b, c)\n",
    "            return np.maximum(0, np.minimum(1, (c - x) / (c - b)))          \n",
    "        elif b == c:  # falling ramp (plateau at a, b)\n",
    "            return np.maximum(0, np.minimum(1, (x - a) / (b - a)))\n",
    "        \n",
    "        # general triangular shape:\n",
    "        return np.maximum(0, np.minimum((x - a) / (b - a), (c - x) / (c - b)))\n",
    "    \n",
    "    def plot_mf(self, max_values, mf_names = None):\n",
    "        # if the user did not provide names:\n",
    "        if mf_names is None:\n",
    "            mf_names = [f'MF {i + 1}' for i in range(self.num_mfs)]\n",
    "        \n",
    "        # make sure that the number of names matches the number of membership functions:\n",
    "        if len(mf_names) != self.num_mfs:\n",
    "            raise ValueError(f'Expected {self.num_mfs} membership functions, but got {len(mf_names)} instead.')\n",
    "        \n",
    "        # make sure that the provided max values match the number of membership functions:\n",
    "        if len(max_values) != self.num_mfs:\n",
    "            raise ValueError(f'Expected {self.num_mfs} max values, but got {len(max_values)} instead.') \n",
    "        \n",
    "        # create linspace based on max values:\n",
    "        input_range = {}\n",
    "        for i in range(self.num_inputs):\n",
    "            input_range[i] = np.linspace(0, max_values[i], 1000)\n",
    "\n",
    "        # plot the mfs:\n",
    "        for input_index in range(self.num_inputs):\n",
    "            x_values = input_range[input_index]\n",
    "            plt.figure(figsize = (12,8))\n",
    "\n",
    "            # plot each mf for the selected input:\n",
    "            for i in range(self.num_mfs):\n",
    "                params = self.mf_params[input_index, i].numpy()\n",
    "                y_values = [self.triangular_membership(x, params) for x in x_values]\n",
    "                plt.plot(x_values, y_values, label = f'{mf_names[i]}')\n",
    "                plt.title(f'Membership Functions for Input X{input_index + 1}')\n",
    "                plt.xlabel('Input Value')\n",
    "                plt.ylabel('Degree of Membership')\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    # need to define the call -> this is what gets executed by the layer:\n",
    "    def call(self, inputs):\n",
    "        # initialize list to hold membership values:\n",
    "        membership_values = []\n",
    "\n",
    "        # loop through each input:\n",
    "        for i in range(self.num_inputs):\n",
    "            input_values = inputs[:, i]   # for a given column, everything in the row\n",
    "            mf_values = []                # initialize list for the MF values of this input\n",
    "\n",
    "            # for every membership function:\n",
    "            for j in range(self.num_mfs):\n",
    "                params = self.mf_params[i, j].numpy()  # extract params\n",
    "\n",
    "                mf_values.append(np.array([self.triangular_membership(x, params) for x in input_values]))\n",
    "\n",
    "            membership_values.append(np.stack(mf_values, axis=-1))  # stack MFs for this input\n",
    "\n",
    "        # combine memberships for all inputs into a single tensor:\n",
    "        membership_values = tf.convert_to_tensor(np.stack(membership_values, axis = 1), dtype = tf.float32)\n",
    "\n",
    "        return membership_values\n",
    "\n",
    "# need to now define the second layer -> the firing strength layer:\n",
    "class FiringStrengthLayer(Layer):\n",
    "    # constructor:\n",
    "    def __init__(self, num_inputs, num_mfs, **kwargs):\n",
    "        super(FiringStrengthLayer, self).__init__(**kwargs)\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_mfs = num_mfs\n",
    "        self.num_rules = num_mfs ** num_inputs\n",
    "\n",
    "    # call function:\n",
    "    def call(self, membership_values):\n",
    "        # get batch size:\n",
    "        batch_size = tf.shape(membership_values)[0]  \n",
    "\n",
    "        # initialize firing strengths\n",
    "        firing_strengths = tf.ones((batch_size, self.num_rules), dtype = tf.float32)    \n",
    "\n",
    "        # generate all rule combinations:\n",
    "        rules = list(product(range(self.num_mfs), repeat = self.num_inputs))  # example: [(0, 0, 0), (0, 0, 1), ...]\n",
    "\n",
    "        # need to check each input, each mf combination, and multiply their values together:\n",
    "        for rule_index, combination in enumerate(rules):\n",
    "            # print(f'rule: {rule_index + 1} | combination: {combination}')\n",
    "            rule_strength = tf.ones((batch_size, ), dtype = tf.float32)\n",
    "\n",
    "            for input_index, mf_index in enumerate(combination):\n",
    "                # print(f'input: {input_index + 1} | mf: {mf_index + 1}')\n",
    "\n",
    "                # correctly extract the fuzzified values based on the combination index:\n",
    "                rule_strength *= membership_values[:, input_index, mf_index]\n",
    "                # print(f'strength: {rule_strength}')\n",
    "            \n",
    "            # update the firing strengths:\n",
    "            firing_strengths = tf.tensor_scatter_nd_update(\n",
    "                firing_strengths,\n",
    "                indices = [[i, rule_index] for i in range(batch_size)],\n",
    "                updates = rule_strength\n",
    "            )\n",
    "\n",
    "        return firing_strengths\n",
    "\n",
    "# need to now define the third layer -> the normalization layer:\n",
    "class NormalizationLayer(Layer):\n",
    "    # constructor:\n",
    "    def __init__(self, num_inputs, num_mfs, **kwargs):\n",
    "        super(NormalizationLayer, self).__init__(**kwargs)\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_mfs = num_mfs\n",
    "        self.num_rules = num_mfs ** num_inputs\n",
    "\n",
    "    # call function:\n",
    "    def call(self, firing_strengths):\n",
    "        # get batch size:\n",
    "        batch_size = tf.shape(firing_strengths)[0]\n",
    "\n",
    "        # get total firing strength:\n",
    "        total_strength = tf.reduce_sum(firing_strengths, axis = 1, keepdims = True)\n",
    "        # print(f'total strength: {total_strength}')\n",
    "        \n",
    "        # normalize the firing strengths:\n",
    "        normalized_strengths = firing_strengths / (total_strength + 1e-10)\n",
    "\n",
    "        return normalized_strengths\n",
    "\n",
    "# need to now define the fourth layer -> the consequent layer:\n",
    "class ConsequentLayer(Layer):\n",
    "    # constructor:\n",
    "    def __init__(self, num_inputs, num_mfs, **kwargs):\n",
    "        super(ConsequentLayer, self).__init__(**kwargs)\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_mfs = num_mfs\n",
    "        self.num_rules = num_mfs ** num_inputs\n",
    "\n",
    "        # need to also initialize the consequent parameters:\n",
    "        self.consequent_params = self.add_weight(\n",
    "            shape = (self.num_rules, self.num_inputs + 1),\n",
    "            initializer = 'random_uniform',\n",
    "            trainable = True,\n",
    "            name = 'Consequent Params'\n",
    "        )\n",
    "\n",
    "    # call function:\n",
    "    def call(self, normalized_strengths, inputs):\n",
    "        # get the batch size\n",
    "        batch_size = tf.shape(normalized_strengths)[0]\n",
    "\n",
    "        # add bias term to inputs: shape (batch_size, num_inputs + 1)\n",
    "        inputs_with_bias = tf.concat([inputs, tf.ones((batch_size, 1), dtype=tf.float32)], axis = -1)\n",
    "\n",
    "        # reshape normalized_strengths to (batch_size, num_rules, 1)\n",
    "        normalized_strengths = tf.reshape(normalized_strengths, (batch_size, self.num_rules, 1))\n",
    "\n",
    "        # get consequent parameters: shape (num_rules, num_inputs + 1)\n",
    "        consequent_params = self.consequent_params  # already initialized as a weight\n",
    "\n",
    "        # expand inputs_with_bias to match the rule axis: (batch_size, num_rules, num_inputs + 1)\n",
    "        inputs_with_bias_expanded = tf.expand_dims(inputs_with_bias, axis = 1)\n",
    "\n",
    "        # calculate the consequent for each rule\n",
    "        consequents = tf.reduce_sum(normalized_strengths * inputs_with_bias_expanded * consequent_params, axis = 2)\n",
    "\n",
    "        return consequents\n",
    "\n",
    "# now can define the final layer -> the output layer:\n",
    "class OutputLayer(Layer):\n",
    "    # constructor:\n",
    "    def __init__(self, num_inputs, num_mfs, **kwargs):\n",
    "        super(OutputLayer, self).__init__(**kwargs)\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_mfs = num_mfs\n",
    "        self.num_rules = num_mfs ** num_inputs\n",
    "\n",
    "    # call function:\n",
    "    def call(self, consequents):\n",
    "        output = tf.reduce_sum(consequents, axis = 1, keepdims = True)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Test by Creating a Model:**\n",
    "\n",
    "This section tests the designed layers by creating a model, adding the custom layers, and testing their operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom parameters have been set.\n"
     ]
    }
   ],
   "source": [
    "# define the following to be used in model generation:\n",
    "num_inputs = 3\n",
    "num_mfs = 3\n",
    "max_values = np.array([10, 25, 50])\n",
    "mf_names = ['Low', 'Medium', 'High']\n",
    "params = np.array([\n",
    "    [  # Parameters for input 1\n",
    "        [0, 0, 6],\n",
    "        [5/6, 5, 55/6],\n",
    "        [4, 10, 10]\n",
    "    ],\n",
    "    [  # Parameters for input 2\n",
    "        [0, 0 , 15],\n",
    "        [25/12, 12.5, 275/12],\n",
    "        [10, 25, 25]\n",
    "    ],\n",
    "    [  # Parameters for input 3\n",
    "        [0, 0, 30],\n",
    "        [25/6, 25, 275/6],\n",
    "        [15, 50, 50]\n",
    "    ]\n",
    "])\n",
    "\n",
    "# generate a model:\n",
    "membership_layer = MembershipFunctionLayer(num_inputs = num_inputs, num_mfs = num_mfs, params = params)\n",
    "firing_layer = FiringStrengthLayer(num_inputs = num_inputs, num_mfs = num_mfs)\n",
    "normalize_layer = NormalizationLayer(num_inputs = num_inputs, num_mfs = num_mfs)\n",
    "consequent_layer = ConsequentLayer(num_inputs = num_inputs, num_mfs = num_mfs)\n",
    "output_layer = OutputLayer(num_inputs = num_inputs, num_mfs = num_mfs)\n",
    "\n",
    "# inputs = tf.constant([[2, 9, 21]], dtype=tf.float32)\n",
    "inputs = tf.constant([[2, 9, 21], [8, 23, 48]], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the membership layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 3), dtype=float32, numpy=\n",
       "array([[[0.6666667 , 0.28000003, 0.        ],\n",
       "        [0.4       , 0.66400003, 0.        ],\n",
       "        [0.3       , 0.808     , 0.17142858]],\n",
       "\n",
       "       [[0.        , 0.28000006, 0.6666667 ],\n",
       "        [0.        , 0.        , 0.8666667 ],\n",
       "        [0.        , 0.        , 0.94285715]]], dtype=float32)>"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzzified = membership_layer(inputs)\n",
    "membership_layer(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the firing strength layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 27), dtype=float32, numpy=\n",
       "array([[0.08000001, 0.21546668, 0.04571429, 0.13280001, 0.35767472,\n",
       "        0.07588572, 0.        , 0.        , 0.        , 0.03360001,\n",
       "        0.09049601, 0.0192    , 0.05577601, 0.15022339, 0.031872  ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.22880006, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54476196]], dtype=float32)>"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strength = firing_layer(fuzzified)\n",
    "firing_layer(fuzzified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the normalization layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 27), dtype=float32, numpy=\n",
       "array([[0.06207765, 0.16719578, 0.03547294, 0.10304889, 0.27754503,\n",
       "        0.05888508, 0.        , 0.        , 0.        , 0.02607261,\n",
       "        0.07022224, 0.01489864, 0.04328054, 0.11656892, 0.02473173,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.29577467, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.7042253 ]], dtype=float32)>"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized = normalize_layer(strength)\n",
    "normalize_layer(strength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the consequent parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04729572 -0.04595019 -0.0057108  -0.04699364]\n",
      " [-0.01836859  0.03044965 -0.02749634  0.01607974]\n",
      " [ 0.03844278 -0.04710747 -0.01416878  0.0391547 ]\n",
      " [ 0.01769887  0.01309712  0.03926111  0.01583094]\n",
      " [ 0.02272772  0.03254446  0.01594887  0.00747609]\n",
      " [-0.01207443  0.00814833 -0.02880533 -0.02333918]\n",
      " [ 0.04398457 -0.00449562 -0.0421129  -0.03623436]\n",
      " [ 0.03132558  0.02107049  0.03359941  0.04900164]\n",
      " [ 0.01475363 -0.02714983 -0.04934368  0.01364467]\n",
      " [ 0.00907121  0.0385304  -0.02278437 -0.02871265]\n",
      " [ 0.04352954  0.0326534   0.03870339  0.01508773]\n",
      " [ 0.00820502  0.00589476 -0.00024415 -0.02275111]\n",
      " [ 0.03455104 -0.01269355 -0.03540701  0.02256818]\n",
      " [ 0.01016203 -0.04972736 -0.04734776 -0.0089632 ]\n",
      " [ 0.04859101  0.02478668 -0.00603422  0.02154685]\n",
      " [ 0.02484589 -0.02680639 -0.04417217 -0.02979548]\n",
      " [-0.01842093  0.03493283  0.01480181 -0.03477363]\n",
      " [ 0.03513122  0.04090301  0.04629245 -0.04597823]\n",
      " [-0.0464687  -0.04537232 -0.01967951 -0.01357601]\n",
      " [-0.0034784  -0.04300468  0.03868094  0.00428692]\n",
      " [-0.02875332 -0.00036105 -0.02139707 -0.0233882 ]\n",
      " [ 0.03924221  0.01856958 -0.00482016  0.00166056]\n",
      " [-0.04879023  0.03871559 -0.02151972  0.02085144]\n",
      " [-0.01580476 -0.01049112  0.0427607  -0.02005377]\n",
      " [ 0.03103209 -0.00905635 -0.0430511   0.01837604]\n",
      " [-0.00277402  0.00894874  0.02885315 -0.04518865]\n",
      " [ 0.00980603 -0.04132982 -0.01419666  0.01482482]]\n"
     ]
    }
   ],
   "source": [
    "print(consequent_layer.consequent_params.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the consequent layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 27), dtype=float32, numpy=\n",
       "array([[-3.0162333e-02, -5.4177064e-02, -2.1477846e-02,  1.0238796e-01,\n",
       "         1.8894097e-01, -3.4098286e-02,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00, -3.7093051e-03,  8.4884547e-02,  6.1955315e-04,\n",
       "        -3.3158034e-02, -1.6675048e-01,  5.3195604e-03,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  1.0050063e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  0.0000000e+00,\n",
       "         0.0000000e+00,  0.0000000e+00, -1.0836284e+00]], dtype=float32)>"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consequents = consequent_layer(normalized, inputs)\n",
    "consequent_layer(normalized, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the output layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[ 0.03861925],\n",
       "       [-0.0786221 ]], dtype=float32)>"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_layer(consequents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
