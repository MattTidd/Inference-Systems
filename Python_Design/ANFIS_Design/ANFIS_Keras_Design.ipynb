{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction:**\n",
    "\n",
    "This file serves to host an attempted Keras implementation of an Adaptive Neuro-Fuzzy Inference System (ANFIS).\n",
    "\n",
    "**Date Created:** 22/01/2025\n",
    "\n",
    "**Date Modified:** 27/01/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import Packages:**\n",
    "\n",
    "This section imports all the necessary packages for the ANFIS implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages:\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from keras.layers import Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Function & Layer Definition:**\n",
    "\n",
    "This section creates the necessary custom functions and layers for this ANFIS implementation within Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected argument value expression (3223514620.py, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 42\u001b[1;36m\u001b[0m\n\u001b[1;33m    initializer =\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected argument value expression\n"
     ]
    }
   ],
   "source": [
    "# need to first define the initial layer -> the membership function layer:\n",
    "class MembershipFunctionLayer(Layer):\n",
    "    # constructor:\n",
    "    def __init__(self, num_inputs, num_mfs, params = None, **kwargs):   # by including **kwargs, we allow for additional arguments from keras, like name or dtype\n",
    "        super(MembershipFunctionLayer, self).__init__(**kwargs)         # we are subclassing from the keras layer -> telling the constructor to make our layer like a keras layer\n",
    "        self.num_inputs = num_inputs            # define the number of inputs to the ANFIS \n",
    "        self.num_mfs = num_mfs                  # define the number of membership functions per input\n",
    "        self.num_rules = num_mfs ** num_inputs  # the number of rules is calculated as such:\n",
    "\n",
    "        # next is the initialization of the antecedent parameters:\n",
    "        if params is not None:\n",
    "            # initialize custom parameters defined by the user:\n",
    "            self.mf_params = self.add_weight(\n",
    "                shape=(self.num_inputs, self.num_mfs, 3),       # define their shape, (num_inputs, num_mfs, 3) as we have 3 params for a triangular mf\n",
    "                initializer=tf.constant_initializer(params),    # initialize as constants from the provided array\n",
    "                trainable=True,                                 # set to trainable\n",
    "                name=\"Antecedent Params\",                       # assign them a name\n",
    "            )\n",
    "            print('Custom parameters have been set.')\n",
    "        else:\n",
    "            # initialize raw membership parameters:\n",
    "            raw_params = self.add_weight(\n",
    "                shape = (self.num_inputs, self.num_mfs, 3),     # define their shape, (num_inputs, num_mfs, 3) as we have 3 params for a triangular mf\n",
    "                initializer = \"random_uniform\",                 # initialize as a random, uniform distribution\n",
    "                trainable = True,                               # set to trainable\n",
    "                name = \"Raw Antecedent Params\",                 # assign them a name \n",
    "            )\n",
    "\n",
    "            # sort the parameters such that a <= b <= c:\n",
    "            sorted_params = tf.sort(raw_params, axis = 1)           # sort such that a <= b <= c\n",
    "            self.mf_params = self.add_weight(                       \n",
    "                shape = (self.num_inputs, self.num_mfs, 3),                     # set the shape: (num_inputs, num_mfs, 3) as we have 3 params for a triangular mf\n",
    "                initializer = tf.constant_initializer(sorted_params.numpy()),   # initialize as the sorted array of params\n",
    "                trainable = True,                                               # set to trainable\n",
    "                name = 'Antecedent Params'                                      # assign them a name\n",
    "            )\n",
    "            print('Random parameters have been set.')\n",
    "        \n",
    "        # need to also initialize the consequent parameters:\n",
    "        self.consequent_params = self.add_weight(\n",
    "            shape = (self.num_rules, self.num_inputs + 1),\n",
    "            initializer = 'random_uniform',\n",
    "            trainable = True,\n",
    "            name = 'Consequent Params'\n",
    "        )\n",
    "\n",
    "    # define the triangular membership function within this layer as this is where it is used:\n",
    "    def triangular_membership(self, x, params):\n",
    "        a, b, c = params        # load params\n",
    "\n",
    "        # throw error if not a < b < c:\n",
    "        if a > b or b > c:\n",
    "            raise ValueError(\"Invalid parameters: Ensure a < b < c.\") \n",
    "    \n",
    "        if a == b:  # rising ramp (plateau at b, c)\n",
    "            return np.maximum(0, np.minimum(1, (c - x) / (c - b)))          \n",
    "        elif b == c:  # falling ramp (plateau at a, b)\n",
    "            return np.maximum(0, np.minimum(1, (x - a) / (b - a)))\n",
    "        \n",
    "        # general triangular shape:\n",
    "        return np.maximum(0, np.minimum((x - a) / (b - a), (c - x) / (c - b)))\n",
    "    \n",
    "    def plot_mf(self, max_values, mf_names = None):\n",
    "        # if the user did not provide names:\n",
    "        if mf_names is None:\n",
    "            mf_names = [f'MF {i + 1}' for i in range(self.num_mfs)]\n",
    "        \n",
    "        # make sure that the number of names matches the number of membership functions:\n",
    "        if len(mf_names) != self.num_mfs:\n",
    "            raise ValueError(f'Expected {self.num_mfs} membership functions, but got {len(mf_names)} instead.')\n",
    "        \n",
    "        # make sure that the provided max values match the number of membership functions:\n",
    "        if len(max_values) != self.num_mfs:\n",
    "            raise ValueError(f'Expected {self.num_mfs} max values, but got {len(max_values)} instead.') \n",
    "        \n",
    "        # create linspace based on max values:\n",
    "        input_range = {}\n",
    "        for i in range(self.num_inputs):\n",
    "            input_range[i] = np.linspace(0, max_values[i], 1000)\n",
    "\n",
    "        # plot the mfs:\n",
    "        for input_index in range(self.num_inputs):\n",
    "            x_values = input_range[input_index]\n",
    "            plt.figure(figsize = (12,8))\n",
    "\n",
    "            # plot each mf for the selected input:\n",
    "            for i in range(self.num_mfs):\n",
    "                params = self.mf_params[input_index, i].numpy()\n",
    "                y_values = [self.triangular_membership(x, params) for x in x_values]\n",
    "                plt.plot(x_values, y_values, label = f'{mf_names[i]}')\n",
    "                plt.title(f'Membership Functions for Input X{input_index + 1}')\n",
    "                plt.xlabel('Input Value')\n",
    "                plt.ylabel('Degree of Membership')\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    # need to define the call -> this is what gets executed by the layer:\n",
    "    def call(self, inputs):\n",
    "        # initialize list to hold membership values:\n",
    "        membership_values = []\n",
    "\n",
    "        # loop through each input:\n",
    "        for i in range(self.num_inputs):\n",
    "            input_values = inputs[:, i]   # for a given column, everything in the row\n",
    "            mf_values = []                # initialize list for the MF values of this input\n",
    "\n",
    "            # for every membership function:\n",
    "            for j in range(self.num_mfs):\n",
    "                params = self.mf_params[i, j].numpy()  # extract params\n",
    "\n",
    "                mf_values.append(np.array([self.triangular_membership(x, params) for x in input_values]))\n",
    "\n",
    "            membership_values.append(np.stack(mf_values, axis=-1))  # stack MFs for this input\n",
    "\n",
    "        # combine memberships for all inputs into a single tensor:\n",
    "        membership_values = tf.convert_to_tensor(np.stack(membership_values, axis = 1), dtype = tf.float32)\n",
    "\n",
    "        return membership_values\n",
    "\n",
    "# need to now define the second layer -> the firing strength layer:\n",
    "class FiringStrengthLayer(Layer):\n",
    "    # constructor:\n",
    "    def __init__(self, num_inputs, num_mfs, **kwargs):\n",
    "        super(FiringStrengthLayer, self).__init__(**kwargs)\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_mfs = num_mfs\n",
    "        self.num_rules = num_mfs ** num_inputs\n",
    "\n",
    "    # call function:\n",
    "    def call(self, membership_values):\n",
    "        # get batch size:\n",
    "        batch_size = tf.shape(membership_values)[0]  \n",
    "\n",
    "        # initialize firing strengths\n",
    "        firing_strengths = tf.ones((batch_size, self.num_rules), dtype = tf.float32)    \n",
    "\n",
    "        # generate all rule combinations:\n",
    "        rules = list(product(range(self.num_mfs), repeat = self.num_inputs))  # example: [(0, 0, 0), (0, 0, 1), ...]\n",
    "\n",
    "        # need to check each input, each mf combination, and multiply their values together:\n",
    "        for rule_index, combination in enumerate(rules):\n",
    "            # print(f'rule: {rule_index + 1} | combination: {combination}')\n",
    "            rule_strength = tf.ones((batch_size, ), dtype = tf.float32)\n",
    "\n",
    "            for input_index, mf_index in enumerate(combination):\n",
    "                # print(f'input: {input_index + 1} | mf: {mf_index + 1}')\n",
    "\n",
    "                # correctly extract the fuzzified values based on the combination index:\n",
    "                rule_strength *= membership_values[:, input_index, mf_index]\n",
    "                # print(f'strength: {rule_strength}')\n",
    "            \n",
    "            # update the firing strengths:\n",
    "            firing_strengths = tf.tensor_scatter_nd_update(\n",
    "                firing_strengths,\n",
    "                indices = [[i, rule_index] for i in range(batch_size)],\n",
    "                updates = rule_strength\n",
    "            )\n",
    "\n",
    "        return firing_strengths\n",
    "\n",
    "# need to now define the third layer -> the normalization layer:\n",
    "class NormalizationLayer(Layer):\n",
    "    # constructor:\n",
    "    def __init__(self, num_inputs, num_mfs, **kwargs):\n",
    "        super(NormalizationLayer, self).__init__(**kwargs)\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_mfs = num_mfs\n",
    "        self.num_rules = num_mfs ** num_inputs\n",
    "\n",
    "    # call function:\n",
    "    def call(self, firing_strengths):\n",
    "        # get batch size:\n",
    "        batch_size = tf.shape(firing_strengths)[0]\n",
    "\n",
    "        # get total firing strength:\n",
    "        total_strength = tf.reduce_sum(firing_strengths, axis = 1, keepdims = True)\n",
    "        # print(f'total strength: {total_strength}')\n",
    "        \n",
    "        # normalize the firing strengths:\n",
    "        normalized_strengths = firing_strengths / (total_strength + 1e-10)\n",
    "\n",
    "        return normalized_strengths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Test by Creating a Model:**\n",
    "\n",
    "This section tests the designed layers by creating a model, adding the custom layers, and testing their operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom parameters have been set.\n"
     ]
    }
   ],
   "source": [
    "# define the following to be used in model generation:\n",
    "num_inputs = 3\n",
    "num_mfs = 3\n",
    "max_values = np.array([10, 25, 50])\n",
    "mf_names = ['Low', 'Medium', 'High']\n",
    "params = np.array([\n",
    "    [  # Parameters for input 1\n",
    "        [0, 0, 6],\n",
    "        [5/6, 5, 55/6],\n",
    "        [4, 10, 10]\n",
    "    ],\n",
    "    [  # Parameters for input 2\n",
    "        [0, 0 , 15],\n",
    "        [25/12, 12.5, 275/12],\n",
    "        [10, 25, 25]\n",
    "    ],\n",
    "    [  # Parameters for input 3\n",
    "        [0, 0, 30],\n",
    "        [25/6, 25, 275/6],\n",
    "        [15, 50, 50]\n",
    "    ]\n",
    "])\n",
    "\n",
    "# generate a model:\n",
    "membership_layer = MembershipFunctionLayer(num_inputs = num_inputs, num_mfs = num_mfs, params = params)\n",
    "firing_layer = FiringStrengthLayer(num_inputs = num_inputs, num_mfs = num_mfs)\n",
    "normalize_layer = NormalizationLayer(num_inputs = num_inputs, num_mfs = num_mfs)\n",
    "\n",
    "# , [8, 23, 48]\n",
    "inputs = tf.constant([[2, 9, 21]], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the membership layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 3), dtype=float32, numpy=\n",
       "array([[[0.6666667 , 0.28000003, 0.        ],\n",
       "        [0.4       , 0.66400003, 0.        ],\n",
       "        [0.3       , 0.808     , 0.17142858]]], dtype=float32)>"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzzified = membership_layer(inputs)\n",
    "membership_layer(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the firing strength layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 27), dtype=float32, numpy=\n",
       "array([[0.08000001, 0.21546668, 0.04571429, 0.13280001, 0.35767472,\n",
       "        0.07588572, 0.        , 0.        , 0.        , 0.03360001,\n",
       "        0.09049601, 0.0192    , 0.05577601, 0.15022339, 0.031872  ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strength = firing_layer(fuzzified)\n",
    "firing_layer(fuzzified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the normalization layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 27), dtype=float32, numpy=\n",
       "array([[0.06207765, 0.16719578, 0.03547294, 0.10304889, 0.27754503,\n",
       "        0.05888508, 0.        , 0.        , 0.        , 0.02607261,\n",
       "        0.07022224, 0.01489864, 0.04328054, 0.11656892, 0.02473173,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized = normalize_layer(strength)\n",
    "normalize_layer(strength)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
