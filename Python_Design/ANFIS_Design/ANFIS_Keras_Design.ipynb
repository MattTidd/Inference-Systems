{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction:**\n",
    "\n",
    "This file serves to host an attempted Keras implementation of an Adaptive Neuro-Fuzzy Inference System (ANFIS).\n",
    "\n",
    "**Date Created:** 22/01/2025\n",
    "\n",
    "**Date Modified:** 28/01/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import Packages:**\n",
    "\n",
    "This section imports all the necessary packages for the ANFIS implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages:\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pickle import dump\n",
    "from itertools import product\n",
    "from keras.layers import Layer\n",
    "from tensorflow.keras import Input, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Function & Layer Definition:**\n",
    "\n",
    "This section creates the necessary custom functions and layers for this ANFIS implementation within Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to first define the initial layer -> the membership function layer:\n",
    "class MembershipFunctionLayer(Layer):\n",
    "    # constructor:\n",
    "    def __init__(self, num_inputs, num_mfs, params = None, **kwargs):   # by including **kwargs, we allow for additional arguments from keras, like name or dtype\n",
    "        super(MembershipFunctionLayer, self).__init__(**kwargs)         # we are subclassing from the keras layer -> telling the constructor to make our layer like a keras layer\n",
    "        self.num_inputs = num_inputs            # define the number of inputs to the ANFIS \n",
    "        self.num_mfs = num_mfs                  # define the number of membership functions per input\n",
    "        self.num_rules = num_mfs ** num_inputs  # the number of rules is calculated as such:\n",
    "\n",
    "        # next is the initialization of the antecedent parameters:\n",
    "        if params is not None:\n",
    "            # initialize custom parameters defined by the user:\n",
    "            self.mf_params = self.add_weight(\n",
    "                shape=(self.num_inputs, self.num_mfs, 3),       # define their shape, (num_inputs, num_mfs, 3) as we have 3 params for a triangular mf\n",
    "                initializer=tf.constant_initializer(params),    # initialize as constants from the provided array\n",
    "                trainable=True,                                 # set to trainable\n",
    "                name=\"Antecedent Params\",                       # assign them a name\n",
    "            )\n",
    "            print('Custom parameters have been set.')\n",
    "        else:\n",
    "            # initialize raw membership parameters:\n",
    "            raw_params = self.add_weight(\n",
    "                shape = (self.num_inputs, self.num_mfs, 3),                                 # define their shape, (num_inputs, num_mfs, 3) \n",
    "                initializer = tf.keras.initializers.RandomUniform(-1.0, 1.0, seed = 1234),  # initialize as a random, uniform distribution\n",
    "                trainable = True,                                                           # set to trainable\n",
    "                name = \"Raw Antecedent Params\",                                             # assign them a name \n",
    "            )\n",
    "\n",
    "            # sort the parameters such that a <= b <= c:\n",
    "            sorted_params = tf.sort(raw_params, axis = 1)           # sort such that a <= b <= c\n",
    "            self.mf_params = self.add_weight(                       \n",
    "                shape = (self.num_inputs, self.num_mfs, 3),                     # set the shape: (num_inputs, num_mfs, 3) as we have 3 params for a triangular mf\n",
    "                initializer = tf.constant_initializer(sorted_params.numpy()),   # initialize as the sorted array of params\n",
    "                trainable = True,                                               # set to trainable\n",
    "                name = 'Antecedent Params'                                      # assign them a name\n",
    "            )\n",
    "            print('Random parameters have been set.')\n",
    " \n",
    "    # function for visualizing the membership functions:\n",
    "    def plot_mf(self, max_values, mf_names = None):\n",
    "        # if the user did not provide names:\n",
    "        if mf_names is None:\n",
    "            mf_names = [f'MF {i + 1}' for i in range(self.num_mfs)]\n",
    "        \n",
    "        # make sure that the number of names matches the number of membership functions:\n",
    "        if len(mf_names) != self.num_mfs:\n",
    "            raise ValueError(f'Expected {self.num_mfs} membership functions, but got {len(mf_names)} instead.')\n",
    "        \n",
    "        # make sure that the provided max values match the number of membership functions:\n",
    "        if len(max_values) != self.num_mfs:\n",
    "            raise ValueError(f'Expected {self.num_mfs} max values, but got {len(max_values)} instead.') \n",
    "        \n",
    "        # create linspace based on max values:\n",
    "        input_range = {}\n",
    "        for i in range(self.num_inputs):\n",
    "            input_range[i] = np.linspace(0, max_values[i], 1000)\n",
    "\n",
    "        # plot the mfs:\n",
    "        for input_index in range(self.num_inputs):\n",
    "            x_values = input_range[input_index]\n",
    "            plt.figure(figsize = (12,8))\n",
    "\n",
    "            # plot each mf for the selected input:\n",
    "            for i in range(self.num_mfs):\n",
    "                params = self.mf_params[input_index, i].numpy()\n",
    "                a, b, c = params\n",
    "                y_values = [np.maximum(0.0, np.minimum((x - a) / (b - a + 1e-6), (c - x) / (c - b + 1e-6))) for x in x_values]\n",
    "                \n",
    "                plt.plot(x_values, y_values, label = f'{mf_names[i]}')\n",
    "            plt.title(f'Membership Functions for Input X{input_index + 1}')\n",
    "            plt.xlabel('Input Value')\n",
    "            plt.ylabel('Degree of Membership')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "        plt.show()\n",
    "    \n",
    "    # need to define the call -> this is what gets executed by the layer:\n",
    "    def call(self, inputs):\n",
    "        # initialize list to hold membership values:\n",
    "        membership_values = []\n",
    "\n",
    "        # loop through each input:\n",
    "        for i in range(self.num_inputs):\n",
    "            # extract membership functions for the current input:\n",
    "            input_mf_params = self.mf_params[i]  # symbolic tensor\n",
    "\n",
    "            # compute membership values for all MFs for the current input:\n",
    "            mf_values = []\n",
    "\n",
    "            for j in range(self.num_mfs):\n",
    "                a = input_mf_params[j, 0]\n",
    "                b = input_mf_params[j, 1]\n",
    "                c = input_mf_params[j, 2]\n",
    "\n",
    "                mf_value = tf.maximum(\n",
    "                    0.0,\n",
    "                    tf.minimum(\n",
    "                        (inputs[:, i] - a) / (b - a + 1e-6),\n",
    "                        (c - inputs[:, i]) / (c - b + 1e-6),\n",
    "                    ),\n",
    "                )\n",
    "                mf_values.append(mf_value)\n",
    "\n",
    "            # stack MFs for this input\n",
    "            membership_values.append(tf.stack(mf_values, axis = -1))\n",
    "\n",
    "        # stack all membership values (shape: batch_size, num_inputs, num_mfs)\n",
    "        return tf.stack(membership_values, axis = 1)\n",
    "\n",
    "# need to now define the second layer -> the firing strength layer:\n",
    "class FiringStrengthLayer(Layer):\n",
    "    # constructor:\n",
    "    def __init__(self, num_inputs, num_mfs, **kwargs):\n",
    "        super(FiringStrengthLayer, self).__init__(**kwargs)\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_mfs = num_mfs\n",
    "        self.num_rules = num_mfs ** num_inputs\n",
    "\n",
    "    # call function:\n",
    "    def call(self, membership_values):\n",
    "        # get batch size:\n",
    "        batch_size = tf.shape(membership_values)[0]  \n",
    "\n",
    "        # initialize firing strengths\n",
    "        firing_strengths = tf.ones((batch_size, self.num_rules), dtype = tf.float32)    \n",
    "\n",
    "        # generate all rule combinations:\n",
    "        rules = list(product(range(self.num_mfs), repeat = self.num_inputs))  # example: [(0, 0, 0), (0, 0, 1), ...]\n",
    "\n",
    "        # need to check each input, each mf combination, and multiply their values together:\n",
    "        for rule_index, combination in enumerate(rules):\n",
    "            # print(f'rule: {rule_index + 1} | combination: {combination}')\n",
    "            rule_strength = tf.ones((batch_size, ), dtype = tf.float32)\n",
    "\n",
    "            for input_index, mf_index in enumerate(combination):\n",
    "                # print(f'input: {input_index + 1} | mf: {mf_index + 1}')\n",
    "\n",
    "                # correctly extract the fuzzified values based on the combination index:\n",
    "                rule_strength *= membership_values[:, input_index, mf_index]\n",
    "                # print(f'strength: {rule_strength}')\n",
    "            \n",
    "            # update the firing strengths:\n",
    "            rule_strength = tf.expand_dims(rule_strength, axis = -1)  # shape: (batch_size, 1)\n",
    "            firing_strengths = tf.concat(\n",
    "                [firing_strengths[:, :rule_index], rule_strength, firing_strengths[:, rule_index + 1:]],\n",
    "                axis = 1,\n",
    "            )\n",
    "\n",
    "        return firing_strengths\n",
    "\n",
    "# need to now define the third layer -> the normalization layer:\n",
    "class NormalizationLayer(Layer):\n",
    "    # constructor:\n",
    "    def __init__(self, num_inputs, num_mfs, **kwargs):\n",
    "        super(NormalizationLayer, self).__init__(**kwargs)\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_mfs = num_mfs\n",
    "        self.num_rules = num_mfs ** num_inputs\n",
    "\n",
    "    # call function:\n",
    "    def call(self, firing_strengths):\n",
    "        # get batch size:\n",
    "        batch_size = tf.shape(firing_strengths)[0]\n",
    "\n",
    "        # get total firing strength:\n",
    "        total_strength = tf.reduce_sum(firing_strengths, axis = 1, keepdims = True)\n",
    "        # print(f'total strength: {total_strength}')\n",
    "        \n",
    "        # normalize the firing strengths:\n",
    "        normalized_strengths = firing_strengths / (total_strength + 1e-10)\n",
    "\n",
    "        return normalized_strengths\n",
    "\n",
    "# need to now define the fourth layer -> the consequent layer:\n",
    "class ConsequentLayer(Layer):\n",
    "    # constructor:\n",
    "    def __init__(self, num_inputs, num_mfs, **kwargs):\n",
    "        super(ConsequentLayer, self).__init__(**kwargs)\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_mfs = num_mfs\n",
    "        self.num_rules = num_mfs ** num_inputs\n",
    "\n",
    "        # need to also initialize the consequent parameters:\n",
    "        self.consequent_params = self.add_weight(\n",
    "            shape = (self.num_rules, self.num_inputs + 1),\n",
    "            initializer = tf.keras.initializers.RandomUniform(-1.0, 1.0, seed = 1234),\n",
    "            trainable = True,\n",
    "            name = 'Consequent Params'\n",
    "        )\n",
    "\n",
    "    # call function:\n",
    "    def call(self, input_list):\n",
    "        # inputs are a list -> extract values:\n",
    "        normalized_strengths, inputs = input_list\n",
    "\n",
    "        # get the batch size\n",
    "        batch_size = tf.shape(normalized_strengths)[0]\n",
    "\n",
    "        # add bias term to inputs: shape (batch_size, num_inputs + 1)\n",
    "        inputs_with_bias = tf.concat([inputs, tf.ones((batch_size, 1), dtype=tf.float32)], axis = -1)\n",
    "\n",
    "        # reshape normalized_strengths to (batch_size, num_rules, 1)\n",
    "        normalized_strengths = tf.reshape(normalized_strengths, (batch_size, self.num_rules, 1))\n",
    "\n",
    "        # get consequent parameters: shape (num_rules, num_inputs + 1)\n",
    "        consequent_params = self.consequent_params  # already initialized as a weight\n",
    "\n",
    "        # expand inputs_with_bias to match the rule axis: (batch_size, num_rules, num_inputs + 1)\n",
    "        inputs_with_bias_expanded = tf.expand_dims(inputs_with_bias, axis = 1)\n",
    "\n",
    "        # calculate the consequent for each rule\n",
    "        consequents = tf.reduce_sum(normalized_strengths * inputs_with_bias_expanded * consequent_params, axis = 2)\n",
    "\n",
    "        return consequents\n",
    "\n",
    "# now can define the final layer -> the output layer:\n",
    "class OutputLayer(Layer):\n",
    "    # constructor:\n",
    "    def __init__(self, num_inputs, num_mfs, **kwargs):\n",
    "        super(OutputLayer, self).__init__(**kwargs)\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_mfs = num_mfs\n",
    "        self.num_rules = num_mfs ** num_inputs\n",
    "\n",
    "    # call function:\n",
    "    def call(self, consequents):\n",
    "        output = tf.reduce_sum(consequents, axis = 1, keepdims = True)\n",
    "        return output\n",
    "\n",
    "# define a custom function for building models:\n",
    "def BuildAnfis(input_shape, num_inputs, num_mfs, antecedent_params = None):\n",
    "    # define the inputs:\n",
    "    inputs = Input(shape = input_shape)\n",
    "\n",
    "    # add the custom layers:\n",
    "    membership_layer = MembershipFunctionLayer(num_inputs = num_inputs, num_mfs = num_mfs, params = antecedent_params)(inputs)\n",
    "    firing_layer = FiringStrengthLayer(num_inputs = num_inputs, num_mfs = num_mfs)(membership_layer)\n",
    "    normalization_layer = NormalizationLayer(num_inputs = num_inputs, num_mfs = num_mfs)(firing_layer)\n",
    "    consequent_layer = ConsequentLayer(num_inputs = num_inputs, num_mfs = num_mfs)([normalization_layer, inputs])\n",
    "    output_layer = OutputLayer(num_inputs = num_inputs, num_mfs = num_mfs)(consequent_layer)\n",
    "\n",
    "    # create and compile the model:\n",
    "    model = Model(inputs = inputs, outputs = output_layer)\n",
    "    model.compile(optimizer = 'adam', loss = 'mse')\n",
    "\n",
    "    print('Model compiled!')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Creation:**\n",
    "\n",
    "This section creates a given model and explores its parameters and structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom parameters have been set.\n",
      "Model compiled!\n"
     ]
    }
   ],
   "source": [
    "# define the following to be used in model generation:\n",
    "num_inputs = 3\n",
    "num_mfs = 3\n",
    "max_values = np.array([10, 25, 50])\n",
    "mf_names = ['Low', 'Medium', 'High']\n",
    "params = np.array([\n",
    "    [  # Parameters for input 1\n",
    "        [0, 0, 6],\n",
    "        [5/6, 5, 55/6],\n",
    "        [4, 10, 10]\n",
    "    ],\n",
    "    [  # Parameters for input 2\n",
    "        [0, 0 , 15],\n",
    "        [25/12, 12.5, 275/12],\n",
    "        [10, 25, 25]\n",
    "    ],\n",
    "    [  # Parameters for input 3\n",
    "        [0, 0, 30],\n",
    "        [25/6, 25, 275/6],\n",
    "        [15, 50, 50]\n",
    "    ]\n",
    "])\n",
    "\n",
    "# # define inputs:\n",
    "# inputs = tf.constant([[2, 9, 21], [8, 23, 48]], dtype=tf.float32)\n",
    "\n",
    "# make model:\n",
    "model = BuildAnfis(input_shape = (3,), num_inputs = num_inputs, num_mfs = num_mfs, antecedent_params = params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the model structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)      </span>┃<span style=\"font-weight: bold\"> Output Shape    </span>┃<span style=\"font-weight: bold\">   Param # </span>┃<span style=\"font-weight: bold\"> Connected to   </span>┃<span style=\"font-weight: bold\"> Trai… </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━┩\n",
       "│ input_layer_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -              │   <span style=\"font-weight: bold\">-</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │                 │           │                │       │\n",
       "├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤\n",
       "│ membership_funct… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span> │ input_layer_4… │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MembershipFunct…</span> │                 │           │                │       │\n",
       "├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤\n",
       "│ firing_strength_… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ membership_fu… │   <span style=\"font-weight: bold\">-</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">FiringStrengthL…</span> │                 │           │                │       │\n",
       "├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤\n",
       "│ normalization_la… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ firing_streng… │   <span style=\"font-weight: bold\">-</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NormalizationLa…</span> │                 │           │                │       │\n",
       "├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤\n",
       "│ consequent_layer… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">108</span> │ normalization… │   <span style=\"color: #00af00; text-decoration-color: #00af00; font-weight: bold\">Y</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConsequentLayer</span>) │                 │           │ input_layer_4… │       │\n",
       "├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤\n",
       "│ output_layer_4    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ consequent_la… │   <span style=\"font-weight: bold\">-</span>   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">OutputLayer</span>)     │                 │           │                │       │\n",
       "└───────────────────┴─────────────────┴───────────┴────────────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m  Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mTrai…\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━┩\n",
       "│ input_layer_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)       │         \u001b[38;5;34m0\u001b[0m │ -              │   \u001b[1m-\u001b[0m   │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)      │                 │           │                │       │\n",
       "├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤\n",
       "│ membership_funct… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │        \u001b[38;5;34m27\u001b[0m │ input_layer_4… │   \u001b[1;38;5;34mY\u001b[0m   │\n",
       "│ (\u001b[38;5;33mMembershipFunct…\u001b[0m │                 │           │                │       │\n",
       "├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤\n",
       "│ firing_strength_… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m)      │         \u001b[38;5;34m0\u001b[0m │ membership_fu… │   \u001b[1m-\u001b[0m   │\n",
       "│ (\u001b[38;5;33mFiringStrengthL…\u001b[0m │                 │           │                │       │\n",
       "├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤\n",
       "│ normalization_la… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m)      │         \u001b[38;5;34m0\u001b[0m │ firing_streng… │   \u001b[1m-\u001b[0m   │\n",
       "│ (\u001b[38;5;33mNormalizationLa…\u001b[0m │                 │           │                │       │\n",
       "├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤\n",
       "│ consequent_layer… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m)      │       \u001b[38;5;34m108\u001b[0m │ normalization… │   \u001b[1;38;5;34mY\u001b[0m   │\n",
       "│ (\u001b[38;5;33mConsequentLayer\u001b[0m) │                 │           │ input_layer_4… │       │\n",
       "├───────────────────┼─────────────────┼───────────┼────────────────┼───────┤\n",
       "│ output_layer_4    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)       │         \u001b[38;5;34m0\u001b[0m │ consequent_la… │   \u001b[1m-\u001b[0m   │\n",
       "│ (\u001b[38;5;33mOutputLayer\u001b[0m)     │                 │           │                │       │\n",
       "└───────────────────┴─────────────────┴───────────┴────────────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">135</span> (540.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m135\u001b[0m (540.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">135</span> (540.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m135\u001b[0m (540.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary(show_trainable = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Import & Processing:**\n",
    "\n",
    "Need to now import the required data and split it into training, validation, and testing. From this, the model can be trained and its performance verified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded\n"
     ]
    }
   ],
   "source": [
    "# get the data path:\n",
    "files_in_dir = os.listdir(os.getcwd())\n",
    "data_path = os.path.join(os.getcwd(), files_in_dir[files_in_dir.index('V3_Data.csv')])\n",
    "\n",
    "# load data based on data path:\n",
    "df = pd.read_csv(data_path)\n",
    "print('Data successfully loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to first split into features and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into X and Y:\n",
    "x_data = df.drop(columns = 'Suitability')\n",
    "y_data = df['Suitability']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data can be split into training, validation, and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8000 training examples\n",
      "There are 1000 validation examples\n",
      "There are 1000 testing examples\n",
      "\n",
      "Input shape is of form: 3\n"
     ]
    }
   ],
   "source": [
    "# split the data using train_test_split:\n",
    "x_train, x_filler, y_train, y_filler = train_test_split(x_data, y_data, test_size = 0.2)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_filler, y_filler, test_size = 0.5)\n",
    "\n",
    "# get the split results:\n",
    "print(f'There are {x_train.shape[0]} training examples')\n",
    "print(f'There are {x_val.shape[0]} validation examples')\n",
    "print(f'There are {x_test.shape[0]} testing examples\\n')\n",
    "\n",
    "# extract the input shape:\n",
    "INPUT_SHAPE = x_data.shape[1]\n",
    "print(f'Input shape is of form: {INPUT_SHAPE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can scale the data. The data must be scaled using the same scaler used on the training set, to ensure that the model is consistent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a scaler:\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# scale each set:\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_val = scaler.transform(x_val)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "# save the scaler:\n",
    "dump(scaler, open('scaler.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
