{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction:**\n",
    "\n",
    "This file serves to host an attempted Keras implementation of an Adaptive Neuro-Fuzzy Inference System (ANFIS).\n",
    "\n",
    "**Date Created:** 22/01/2025\n",
    "\n",
    "**Date Modified:** 27/01/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Import Packages:**\n",
    "\n",
    "This section imports all the necessary packages for the ANFIS implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages:\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from keras.layers import Layer\n",
    "from tensorflow.keras import Input, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Function & Layer Definition:**\n",
    "\n",
    "This section creates the necessary custom functions and layers for this ANFIS implementation within Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to first define the initial layer -> the membership function layer:\n",
    "class MembershipFunctionLayer(Layer):\n",
    "    # constructor:\n",
    "    def __init__(self, num_inputs, num_mfs, params = None, **kwargs):   # by including **kwargs, we allow for additional arguments from keras, like name or dtype\n",
    "        super(MembershipFunctionLayer, self).__init__(**kwargs)         # we are subclassing from the keras layer -> telling the constructor to make our layer like a keras layer\n",
    "        self.num_inputs = num_inputs            # define the number of inputs to the ANFIS \n",
    "        self.num_mfs = num_mfs                  # define the number of membership functions per input\n",
    "        self.num_rules = num_mfs ** num_inputs  # the number of rules is calculated as such:\n",
    "\n",
    "        # next is the initialization of the antecedent parameters:\n",
    "        if params is not None:\n",
    "            # initialize custom parameters defined by the user:\n",
    "            self.mf_params = self.add_weight(\n",
    "                shape=(self.num_inputs, self.num_mfs, 3),       # define their shape, (num_inputs, num_mfs, 3) as we have 3 params for a triangular mf\n",
    "                initializer=tf.constant_initializer(params),    # initialize as constants from the provided array\n",
    "                trainable=True,                                 # set to trainable\n",
    "                name=\"Antecedent Params\",                       # assign them a name\n",
    "            )\n",
    "            print('Custom parameters have been set.')\n",
    "        else:\n",
    "            # initialize raw membership parameters:\n",
    "            raw_params = self.add_weight(\n",
    "                shape = (self.num_inputs, self.num_mfs, 3),                                 # define their shape, (num_inputs, num_mfs, 3) \n",
    "                initializer = tf.keras.initializers.RandomUniform(-1.0, 1.0, seed = 1234),  # initialize as a random, uniform distribution\n",
    "                trainable = True,                                                           # set to trainable\n",
    "                name = \"Raw Antecedent Params\",                                             # assign them a name \n",
    "            )\n",
    "\n",
    "            # sort the parameters such that a <= b <= c:\n",
    "            sorted_params = tf.sort(raw_params, axis = 1)           # sort such that a <= b <= c\n",
    "            self.mf_params = self.add_weight(                       \n",
    "                shape = (self.num_inputs, self.num_mfs, 3),                     # set the shape: (num_inputs, num_mfs, 3) as we have 3 params for a triangular mf\n",
    "                initializer = tf.constant_initializer(sorted_params.numpy()),   # initialize as the sorted array of params\n",
    "                trainable = True,                                               # set to trainable\n",
    "                name = 'Antecedent Params'                                      # assign them a name\n",
    "            )\n",
    "            print('Random parameters have been set.')\n",
    " \n",
    "    # function for visualizing the membership functions:\n",
    "    def plot_mf(self, max_values, mf_names = None):\n",
    "        # if the user did not provide names:\n",
    "        if mf_names is None:\n",
    "            mf_names = [f'MF {i + 1}' for i in range(self.num_mfs)]\n",
    "        \n",
    "        # make sure that the number of names matches the number of membership functions:\n",
    "        if len(mf_names) != self.num_mfs:\n",
    "            raise ValueError(f'Expected {self.num_mfs} membership functions, but got {len(mf_names)} instead.')\n",
    "        \n",
    "        # make sure that the provided max values match the number of membership functions:\n",
    "        if len(max_values) != self.num_mfs:\n",
    "            raise ValueError(f'Expected {self.num_mfs} max values, but got {len(max_values)} instead.') \n",
    "        \n",
    "        # create linspace based on max values:\n",
    "        input_range = {}\n",
    "        for i in range(self.num_inputs):\n",
    "            input_range[i] = np.linspace(0, max_values[i], 1000)\n",
    "\n",
    "        # plot the mfs:\n",
    "        for input_index in range(self.num_inputs):\n",
    "            x_values = input_range[input_index]\n",
    "            plt.figure(figsize = (12,8))\n",
    "\n",
    "            # plot each mf for the selected input:\n",
    "            for i in range(self.num_mfs):\n",
    "                params = self.mf_params[input_index, i].numpy()\n",
    "                a, b, c = params\n",
    "                y_values = [np.maximum(0.0, np.minimum((x - a) / (b - a + 1e-6), (c - x) / (c - b + 1e-6))) for x in x_values]\n",
    "                \n",
    "                plt.plot(x_values, y_values, label = f'{mf_names[i]}')\n",
    "            plt.title(f'Membership Functions for Input X{input_index + 1}')\n",
    "            plt.xlabel('Input Value')\n",
    "            plt.ylabel('Degree of Membership')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "        plt.show()\n",
    "    \n",
    "    # need to define the call -> this is what gets executed by the layer:\n",
    "    def call(self, inputs):\n",
    "        # initialize list to hold membership values:\n",
    "        membership_values = []\n",
    "\n",
    "        # loop through each input:\n",
    "        for i in range(self.num_inputs):\n",
    "            # extract membership functions for the current input:\n",
    "            input_mf_params = self.mf_params[i]  # symbolic tensor\n",
    "\n",
    "            # compute membership values for all MFs for the current input:\n",
    "            mf_values = []\n",
    "\n",
    "            for j in range(self.num_mfs):\n",
    "                a = input_mf_params[j, 0]\n",
    "                b = input_mf_params[j, 1]\n",
    "                c = input_mf_params[j, 2]\n",
    "\n",
    "                mf_value = tf.maximum(\n",
    "                    0.0,\n",
    "                    tf.minimum(\n",
    "                        (inputs[:, i] - a) / (b - a + 1e-6),\n",
    "                        (c - inputs[:, i]) / (c - b + 1e-6),\n",
    "                    ),\n",
    "                )\n",
    "                mf_values.append(mf_value)\n",
    "\n",
    "            # stack MFs for this input\n",
    "            membership_values.append(tf.stack(mf_values, axis = -1))\n",
    "\n",
    "        # stack all membership values (shape: batch_size, num_inputs, num_mfs)\n",
    "        return tf.stack(membership_values, axis = 1)\n",
    "\n",
    "# need to now define the second layer -> the firing strength layer:\n",
    "class FiringStrengthLayer(Layer):\n",
    "    # constructor:\n",
    "    def __init__(self, num_inputs, num_mfs, **kwargs):\n",
    "        super(FiringStrengthLayer, self).__init__(**kwargs)\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_mfs = num_mfs\n",
    "        self.num_rules = num_mfs ** num_inputs\n",
    "\n",
    "    # call function:\n",
    "    def call(self, membership_values):\n",
    "        # get batch size:\n",
    "        batch_size = tf.shape(membership_values)[0]  \n",
    "\n",
    "        # initialize firing strengths\n",
    "        firing_strengths = tf.ones((batch_size, self.num_rules), dtype = tf.float32)    \n",
    "\n",
    "        # generate all rule combinations:\n",
    "        rules = list(product(range(self.num_mfs), repeat = self.num_inputs))  # example: [(0, 0, 0), (0, 0, 1), ...]\n",
    "\n",
    "        # need to check each input, each mf combination, and multiply their values together:\n",
    "        for rule_index, combination in enumerate(rules):\n",
    "            # print(f'rule: {rule_index + 1} | combination: {combination}')\n",
    "            rule_strength = tf.ones((batch_size, ), dtype = tf.float32)\n",
    "\n",
    "            for input_index, mf_index in enumerate(combination):\n",
    "                # print(f'input: {input_index + 1} | mf: {mf_index + 1}')\n",
    "\n",
    "                # correctly extract the fuzzified values based on the combination index:\n",
    "                rule_strength *= membership_values[:, input_index, mf_index]\n",
    "                # print(f'strength: {rule_strength}')\n",
    "            \n",
    "            # update the firing strengths:\n",
    "            rule_strength = tf.expand_dims(rule_strength, axis = -1)  # shape: (batch_size, 1)\n",
    "            firing_strengths = tf.concat(\n",
    "                [firing_strengths[:, :rule_index], rule_strength, firing_strengths[:, rule_index + 1:]],\n",
    "                axis = 1,\n",
    "            )\n",
    "\n",
    "        return firing_strengths\n",
    "\n",
    "# need to now define the third layer -> the normalization layer:\n",
    "class NormalizationLayer(Layer):\n",
    "    # constructor:\n",
    "    def __init__(self, num_inputs, num_mfs, **kwargs):\n",
    "        super(NormalizationLayer, self).__init__(**kwargs)\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_mfs = num_mfs\n",
    "        self.num_rules = num_mfs ** num_inputs\n",
    "\n",
    "    # call function:\n",
    "    def call(self, firing_strengths):\n",
    "        # get batch size:\n",
    "        batch_size = tf.shape(firing_strengths)[0]\n",
    "\n",
    "        # get total firing strength:\n",
    "        total_strength = tf.reduce_sum(firing_strengths, axis = 1, keepdims = True)\n",
    "        # print(f'total strength: {total_strength}')\n",
    "        \n",
    "        # normalize the firing strengths:\n",
    "        normalized_strengths = firing_strengths / (total_strength + 1e-10)\n",
    "\n",
    "        return normalized_strengths\n",
    "\n",
    "# need to now define the fourth layer -> the consequent layer:\n",
    "class ConsequentLayer(Layer):\n",
    "    # constructor:\n",
    "    def __init__(self, num_inputs, num_mfs, **kwargs):\n",
    "        super(ConsequentLayer, self).__init__(**kwargs)\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_mfs = num_mfs\n",
    "        self.num_rules = num_mfs ** num_inputs\n",
    "\n",
    "        # need to also initialize the consequent parameters:\n",
    "        self.consequent_params = self.add_weight(\n",
    "            shape = (self.num_rules, self.num_inputs + 1),\n",
    "            initializer = tf.keras.initializers.RandomUniform(-1.0, 1.0, seed = 1234),\n",
    "            trainable = True,\n",
    "            name = 'Consequent Params'\n",
    "        )\n",
    "\n",
    "    # call function:\n",
    "    def call(self, input_list):\n",
    "        # inputs are a list -> extract values:\n",
    "        normalized_strengths, inputs = input_list\n",
    "\n",
    "        # get the batch size\n",
    "        batch_size = tf.shape(normalized_strengths)[0]\n",
    "\n",
    "        # add bias term to inputs: shape (batch_size, num_inputs + 1)\n",
    "        inputs_with_bias = tf.concat([inputs, tf.ones((batch_size, 1), dtype=tf.float32)], axis = -1)\n",
    "\n",
    "        # reshape normalized_strengths to (batch_size, num_rules, 1)\n",
    "        normalized_strengths = tf.reshape(normalized_strengths, (batch_size, self.num_rules, 1))\n",
    "\n",
    "        # get consequent parameters: shape (num_rules, num_inputs + 1)\n",
    "        consequent_params = self.consequent_params  # already initialized as a weight\n",
    "\n",
    "        # expand inputs_with_bias to match the rule axis: (batch_size, num_rules, num_inputs + 1)\n",
    "        inputs_with_bias_expanded = tf.expand_dims(inputs_with_bias, axis = 1)\n",
    "\n",
    "        # calculate the consequent for each rule\n",
    "        consequents = tf.reduce_sum(normalized_strengths * inputs_with_bias_expanded * consequent_params, axis = 2)\n",
    "\n",
    "        return consequents\n",
    "\n",
    "# now can define the final layer -> the output layer:\n",
    "class OutputLayer(Layer):\n",
    "    # constructor:\n",
    "    def __init__(self, num_inputs, num_mfs, **kwargs):\n",
    "        super(OutputLayer, self).__init__(**kwargs)\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_mfs = num_mfs\n",
    "        self.num_rules = num_mfs ** num_inputs\n",
    "\n",
    "    # call function:\n",
    "    def call(self, consequents):\n",
    "        output = tf.reduce_sum(consequents, axis = 1, keepdims = True)\n",
    "        return output\n",
    "\n",
    "# define a custom function for building models:\n",
    "def BuildAnfis(input_shape, num_inputs, num_mfs, antecedent_params = None):\n",
    "    # define the inputs:\n",
    "    inputs = Input(shape = input_shape)\n",
    "\n",
    "    # add the custom layers:\n",
    "    membership_layer = MembershipFunctionLayer(num_inputs = num_inputs, num_mfs = num_mfs, params = antecedent_params)(inputs)\n",
    "    firing_layer = FiringStrengthLayer(num_inputs = num_inputs, num_mfs = num_mfs)(membership_layer)\n",
    "    normalization_layer = NormalizationLayer(num_inputs = num_inputs, num_mfs = num_mfs)(firing_layer)\n",
    "    consequent_layer = ConsequentLayer(num_inputs = num_inputs, num_mfs = num_mfs)([normalization_layer, inputs])\n",
    "    output_layer = OutputLayer(num_inputs = num_inputs, num_mfs = num_mfs)(consequent_layer)\n",
    "\n",
    "    # create and compile the model:\n",
    "    model = Model(inputs = inputs, outputs = output_layer)\n",
    "    model.compile(optimizer = 'adam', loss = 'mse')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Test by Creating a Model:**\n",
    "\n",
    "This section tests the designed layers by creating a model, adding the custom layers, and testing their operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom parameters have been set.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[  5.2075863],\n",
       "       [-35.601593 ]], dtype=float32)>"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the following to be used in model generation:\n",
    "num_inputs = 3\n",
    "num_mfs = 3\n",
    "max_values = np.array([10, 25, 50])\n",
    "mf_names = ['Low', 'Medium', 'High']\n",
    "params = np.array([\n",
    "    [  # Parameters for input 1\n",
    "        [0, 0, 6],\n",
    "        [5/6, 5, 55/6],\n",
    "        [4, 10, 10]\n",
    "    ],\n",
    "    [  # Parameters for input 2\n",
    "        [0, 0 , 15],\n",
    "        [25/12, 12.5, 275/12],\n",
    "        [10, 25, 25]\n",
    "    ],\n",
    "    [  # Parameters for input 3\n",
    "        [0, 0, 30],\n",
    "        [25/6, 25, 275/6],\n",
    "        [15, 50, 50]\n",
    "    ]\n",
    "])\n",
    "\n",
    "# define inputs:\n",
    "inputs = tf.constant([[2, 9, 21], [8, 23, 48]], dtype=tf.float32)\n",
    "\n",
    "# make model:\n",
    "model = BuildAnfis(input_shape = (3,), num_inputs = num_inputs, num_mfs = num_mfs, antecedent_params = params)\n",
    "\n",
    "# get outputs:\n",
    "model(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the membership layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom parameters have been set.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 3), dtype=float32, numpy=\n",
       "array([[[0.66666657, 0.27999997, 0.        ],\n",
       "        [0.39999998, 0.664     , 0.        ],\n",
       "        [0.29999998, 0.8079999 , 0.17142858]],\n",
       "\n",
       "       [[0.        , 0.28      , 0.66666657],\n",
       "        [0.        , 0.        , 0.8666666 ],\n",
       "        [0.        , 0.        , 0.94285715]]], dtype=float32)>"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if first layer is working:\n",
    "membership_layer = MembershipFunctionLayer(num_inputs = num_inputs, num_mfs = num_mfs, params = params)\n",
    "fuzzified = membership_layer(inputs)\n",
    "membership_layer(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the firing strength layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 27), dtype=float32, numpy=\n",
       "array([[0.07999998, 0.2154666 , 0.04571428, 0.13279997, 0.35767457,\n",
       "        0.07588571, 0.        , 0.        , 0.        , 0.03359999,\n",
       "        0.09049597, 0.0192    , 0.05577599, 0.15022331, 0.031872  ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.22879998, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54476184]], dtype=float32)>"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the second layer is working:\n",
    "firing_layer = FiringStrengthLayer(num_inputs = num_inputs, num_mfs = num_mfs)\n",
    "firing_strengths = firing_layer(fuzzified)\n",
    "firing_layer(fuzzified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the normalization layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 27), dtype=float32, numpy=\n",
       "array([[0.06207765, 0.16719578, 0.03547294, 0.10304889, 0.277545  ,\n",
       "        0.05888509, 0.        , 0.        , 0.        , 0.02607261,\n",
       "        0.07022223, 0.01489864, 0.04328054, 0.1165689 , 0.02473174,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.29577467, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.7042253 ]], dtype=float32)>"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the third layer is working:\n",
    "normalization_layer = NormalizationLayer(num_inputs = num_inputs, num_mfs = num_mfs)\n",
    "normalized_strengths = normalization_layer(firing_strengths)\n",
    "normalization_layer(firing_strengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the consequent layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.4833429   0.94353104 -0.59347796  0.5719526 ]\n",
      " [-0.1602943  -0.57636666 -0.06291223  0.97578955]\n",
      " [ 0.95712924 -0.56576324 -0.04465389  0.14160037]\n",
      " [-0.3955686   0.620692   -0.16572523 -0.45917416]\n",
      " [ 0.23653316 -0.10324883  0.6583593   0.51927114]\n",
      " [ 0.85891724  0.5842984   0.35745978 -0.39136028]\n",
      " [ 0.8714628   0.25307345  0.20695925 -0.59601593]\n",
      " [ 0.41705108 -0.05891275  0.7861247   0.9179456 ]\n",
      " [-0.20100307  0.94271064  0.07464957 -0.31705236]\n",
      " [-0.703985    0.496001   -0.2919085  -0.02739382]\n",
      " [-0.8767364  -0.18578386  0.9853842   0.08783364]\n",
      " [ 0.06770396 -0.86160994 -0.00993347  0.85034776]\n",
      " [-0.04560423  0.15610456  0.6566634  -0.42805338]\n",
      " [ 0.87337327  0.30730963 -0.41886377  0.72499156]\n",
      " [ 0.91265917  0.43432903  0.6164298  -0.43405986]\n",
      " [-0.0565145  -0.38930726 -0.25161576 -0.5253489 ]\n",
      " [-0.5949986  -0.45994353 -0.6513028   0.9513335 ]\n",
      " [-0.80386853 -0.91236234 -0.55716157 -0.7829058 ]\n",
      " [ 0.8719275   0.16804814  0.3119259  -0.17928267]\n",
      " [-0.5563867   0.7379923  -0.3891585   0.3008995 ]\n",
      " [-0.7842617   0.8060324   0.28778744 -0.89052415]\n",
      " [-0.540231    0.5373895   0.8307109   0.1418376 ]\n",
      " [-0.4294772   0.9228785   0.80696106  0.3051846 ]\n",
      " [-0.30567193 -0.24591136 -0.18977857  0.78790545]\n",
      " [-0.37644506  0.29767036 -0.97579193  0.26986623]\n",
      " [-0.69638777  0.08395982  0.39000773  0.51780796]\n",
      " [-0.18838215 -0.39257073 -0.34294438 -0.48113346]]\n"
     ]
    }
   ],
   "source": [
    "# create fourth layer:\n",
    "consequent_layer = ConsequentLayer(num_inputs = num_inputs, num_mfs = num_mfs)\n",
    "\n",
    "# check consequent params:\n",
    "print(consequent_layer.consequent_params.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 27), dtype=float32, numpy=\n",
       "array([[ -0.15101129,  -0.9786396 ,  -0.1409603 ,   0.08817759,\n",
       "          3.8547235 ,   0.8297978 ,   0.        ,   0.        ,\n",
       "          0.        ,  -0.08086246,   1.2187331 ,  -0.1039528 ,\n",
       "          0.6351684 ,  -0.41482383,   0.45123664,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        , -16.250435  ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        , -19.35116   ]], dtype=float32)>"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now check consequent output:\n",
    "consequents = consequent_layer([normalized_strengths, inputs])\n",
    "consequent_layer([normalized_strengths, inputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the output layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[  5.2075863],\n",
       "       [-35.601593 ]], dtype=float32)>"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the final layer:\n",
    "output_layer = OutputLayer(num_inputs = num_inputs, num_mfs = num_mfs)\n",
    "output = output_layer(consequents)\n",
    "output_layer(consequents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
